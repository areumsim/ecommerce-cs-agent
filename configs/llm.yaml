# LLM 설정 파일
# API 키는 아래에 직접 입력하거나 환경변수로 설정 가능

# 사용할 프로바이더 선택: openai | anthropic | local
provider: openai

# OpenAI 설정
openai:
  api_key: ""  # 여기에 API 키 입력 또는 OPENAI_API_KEY 환경변수 사용
  model: gpt-4o-mini
  temperature: 0.7
  max_tokens: 1024
  timeout: 30

# Anthropic (Claude) 설정
anthropic:
  api_key: ""  # 여기에 API 키 입력 또는 ANTHROPIC_API_KEY 환경변수 사용
  model: claude-3-haiku-20240307
  temperature: 0.7
  max_tokens: 1024
  timeout: 30

# 로컬 LLM 설정 (vLLM, Ollama 등)
local:
  base_url: http://localhost:8080/v1
  model: local-model
  temperature: 0.7
  max_tokens: 1024
  timeout: 60

# Google AI (Gemini) 설정
google:
  api_key: ""  # 여기에 API 키 입력 또는 GOOGLE_API_KEY 환경변수 사용
  model: gemini-1.5-flash
  temperature: 0.7
  max_tokens: 1024
  timeout: 30

# 시스템 프롬프트 경로
prompts:
  system: configs/prompts/system.txt
  order: configs/prompts/order.txt
  claim: configs/prompts/claim.txt
  policy: configs/prompts/policy.txt
  intent_classification: configs/prompts/intent_classification.txt


# 라우팅 규칙 (의도/카테고리별로 LLM 선택)
routing:
  enabled: true
  rules:
    - when:
        intents: ["policy", "claim", "order"]
      provider: local
    - when:
        intents: ["general", "product_info", "unknown"]
      provider: openai
  fallback:
    provider: openai
